{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Pytorch-basics.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZATq1kLL9Lrn",
        "colab_type": "text"
      },
      "source": [
        "# Includes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPqgDuxJ80BA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iQvFE9f9oO3",
        "colab_type": "text"
      },
      "source": [
        "# Basic Autograd "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQo-Ih4E9S6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "115a1e24-0eb4-4c5c-8077-ad4761994f53"
      },
      "source": [
        "# Example 1 (Linear 1D) \n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)\n",
        "\n",
        "y = w*x + b\n",
        "\n",
        "# Backprop\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print(x.grad)    \n",
        "print(w.grad)    \n",
        "print(b.grad)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ1jXXQA-lme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "471f8ce8-6247-4853-d4f7-bbfdf3996dce"
      },
      "source": [
        "# Example 2 (Linear Regression)\n",
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "\n",
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "print ('w: ', linear.weight)\n",
        "print ('b: ', linear.bias)\n",
        "\n",
        "# Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)\n",
        "print(x.grad)\n",
        "\n",
        "# 1-step gradient descent.\n",
        "optimizer.step()\n",
        "\n",
        "# You can also perform gradient descent at the low level.\n",
        "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 0.3400, -0.4674,  0.4258],\n",
            "        [-0.1894,  0.1355,  0.5381]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([ 0.4912, -0.1716], requires_grad=True)\n",
            "loss:  2.7776167392730713\n",
            "dL/dw:  tensor([[ 0.1939, -0.8835,  2.2192],\n",
            "        [ 0.1195, -0.0944,  1.6635]])\n",
            "dL/db:  tensor([-0.0812,  0.0424])\n",
            "None\n",
            "loss after 1 step optimization:  2.6930313110351562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkkJtShhA8Ed",
        "colab_type": "text"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-W9-HEhA_KW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1b59459e-c24f-484e-b1f8-62df58812e1c"
      },
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "\n",
        "# Convert np array to tensor\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# tensor to np array\n",
        "z = y.numpy()\n",
        "\n",
        "\n",
        "##### SETTING UP A PIPELINE FOR STANDARD DATASETS ######\n",
        "# Download and construct CIFAR-10 dataset.\n",
        "# The transforms.ToTenssor() option converts PIL images or np arrays in range 0 to 255 (HxWxC) to normalized [0,1] (CxHxW) \n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transforms.ToTensor(),\n",
        "                                             download=True)\n",
        "\n",
        "# Fetch one data pair (read data from disk).\n",
        "image, label = train_dataset[0]\n",
        "print (image.size())\n",
        "print (label)\n",
        "\n",
        "# Data loader (this provides queues and threads in a very simple way).\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)\n",
        "\n",
        "# When iteration starts, queue and thread start to load data from files.\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "# Mini-batch images and labels.\n",
        "# every call to next() gives us 64 pairs\n",
        "images, labels = data_iter.next()\n",
        "print(labels.shape) # Will print 64\n",
        "\n",
        "# Actual usage of the data loader is as below.\n",
        "for images, labels in train_loader:\n",
        "    # Training code should be written here.\n",
        "    pass\n",
        "\n",
        "########### Pipeline for a custom dataset ############\n",
        "# You should build your custom dataset as below.\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        # TODO\n",
        "        # 1. Initialize file paths or a list of file names. \n",
        "        pass\n",
        "    def __getitem__(self, index):\n",
        "        # TODO\n",
        "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "        # 3. Return a data pair (e.g. image and label).\n",
        "        pass\n",
        "    def __len__(self):\n",
        "        # You should change 0 to the total size of your dataset.\n",
        "        return 0 \n",
        "\n",
        "# You can then use the prebuilt data loader. \n",
        "custom_dataset = CustomDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)\n",
        "\n",
        "############### Loading a Pretrained model ###############\n",
        "# Download and load the pretrained ResNet-18.\n",
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# If you want to finetune only the top layer of the model, set as below.\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the top layer for finetuning.\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
        "\n",
        "# Forward pass.\n",
        "images = torch.randn(64, 3, 224, 224)\n",
        "outputs = resnet(images)\n",
        "print (outputs.size())     # (64, 100)\n",
        "\n",
        "print(resnet.fc.out_features)\n",
        "\n",
        "####### Saving and Loading a model ##########\n",
        "# Save and load the entire model.\n",
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "# Save and load only the model parameters (recommended).\n",
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([3, 32, 32])\n",
            "6\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "\n",
            "  0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[A\n",
            " 23%|██▎       | 10.1M/44.7M [00:00<00:00, 106MB/s]\u001b[A\n",
            " 45%|████▍     | 19.9M/44.7M [00:00<00:00, 105MB/s]\u001b[A\n",
            " 67%|██████▋   | 29.9M/44.7M [00:00<00:00, 105MB/s]\u001b[A\n",
            " 90%|████████▉ | 40.0M/44.7M [00:00<00:00, 105MB/s]\u001b[A\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 103MB/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 100])\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0tIw0EQGYpN",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqau2RTUGfk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "e6a8b3f8-a589-4ec5-9cc2-ffbeaaf68387"
      },
      "source": [
        "# Hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "num_epochs = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Toy dataset\n",
        "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
        "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
        "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
        "\n",
        "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
        "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
        "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
        "\n",
        "# Linear regression model (1x1 linear layer)\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Convert numpy arrays to torch tensors\n",
        "    inputs = torch.from_numpy(x_train)\n",
        "    targets = torch.from_numpy(y_train)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    \n",
        "    # Backward and optimize\n",
        "    # Zero gradients from previous iterations\n",
        "    optimizer.zero_grad()\n",
        "    # Backprop\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "# Plot the graph\n",
        "#Final predictions after training\n",
        "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
        "# True graph\n",
        "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
        "# Predicted graph\n",
        "plt.plot(x_train, predicted, label='Fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [5/60], Loss: 0.5435\n",
            "Epoch [10/60], Loss: 0.4876\n",
            "Epoch [15/60], Loss: 0.4645\n",
            "Epoch [20/60], Loss: 0.4547\n",
            "Epoch [25/60], Loss: 0.4503\n",
            "Epoch [30/60], Loss: 0.4481\n",
            "Epoch [35/60], Loss: 0.4468\n",
            "Epoch [40/60], Loss: 0.4459\n",
            "Epoch [45/60], Loss: 0.4451\n",
            "Epoch [50/60], Loss: 0.4443\n",
            "Epoch [55/60], Loss: 0.4436\n",
            "Epoch [60/60], Loss: 0.4429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXiU1fn/8fcNRCKLoogVWUwquCBL\ngLhQXFBAEShaXFtqqz9b6k6/bkWhSlEQq1+XXi5841L0kmoVNyxqXQBRVGpAkM0FJGgQZbEsMYIB\n7t8fMw6ZIcskmeSZ5fO6rlyZ58zJMzeTcOfkPOe5j7k7IiKS+hoFHYCIiCSGErqISJpQQhcRSRNK\n6CIiaUIJXUQkTSihi4ikibgTupk1NrMPzexfFTx3oZmtN7OF4Y/fJTZMERGpTpMa9B0FLAf2qeT5\nf7r7FfGe7IADDvCcnJwavLyIiMyfP3+Du7ep6Lm4ErqZtQeGABOAqxMRVE5ODoWFhYk4lYhIxjCz\n1ZU9F++Uyz3A9cCuKvqcZWYfmdk0M+tQkwBFRKTuqk3oZjYUWOfu86vo9hKQ4+7dgdeBxyo510gz\nKzSzwvXr19cqYBERqVg8I/S+wDAzKwKeAk4xsyfKd3D3je6+PXz4MNC7ohO5e4G757t7fps2FU4B\niYhILVU7h+7uNwA3AJhZP+Bad/91+T5m1tbd14YPhxG6eFpjZWVlFBcXs23bttp8uSRYdnY27du3\nJysrK+hQRCQONVnlEsXMxgOF7j4duMrMhgE7gG+BC2tzzuLiYlq2bElOTg5mVtvQJAHcnY0bN1Jc\nXExubm7Q4YhIHGqU0N19NjA7/Pimcu2RUXxdbNu2Tck8SZgZrVu3Rtc6RFJH0t0pqmSePPS9EEkt\nSZfQRUTS1bayndz1+qd8ten7ejm/EnqM4uJizjjjDDp37syhhx7KqFGj+OGHHyrs+9VXX3H22WdX\ne87BgwezadOmWsUzbtw47rzzzmr7tWjRosrnN23axAMPPFCrGESk7p4u/JIj/vwqf3vzM+Z8Wj9T\nmamd0KdOhZwcaNQo9Hnq1Dqdzt0ZPnw4Z555Jp999hmffvopJSUljBkzZo++O3bs4OCDD2batGnV\nnvfll1+mVatWdYqtrpTQRYKx+fsyckbP4PppHwFwZt7BnH9Mx3p5rdRN6FOnwsiRsHo1uIc+jxxZ\np6Q+c+ZMsrOzueiiiwBo3Lgxd999N48++iilpaVMmTKFYcOGccopp9C/f3+Kioro2rUrAKWlpZx7\n7rl06dKFX/ziFxx77LGR0gY5OTls2LCBoqIijjzySH7/+99z1FFHceqpp/L996E/vR566CGOPvpo\nevTowVlnnUVpaWmVsa5atYo+ffrQrVs3xo4dG2kvKSmhf//+9OrVi27duvHiiy8CMHr0aFauXEle\nXh7XXXddpf1EJHEmv7WSHn95LXI857qTuef8nvX2eqmb0MeMgdikV1oaaq+lpUuX0rt39D1R++yz\nDx07dmTFihUALFiwgGnTpvHWW29F9XvggQfYb7/9WLZsGbfccgvz51d8Y+1nn33G5ZdfztKlS2nV\nqhXPPvssAMOHD+eDDz5g0aJFHHnkkTzyyCNVxjpq1CguvfRSFi9eTNu2bSPt2dnZPP/88yxYsIBZ\ns2ZxzTXX4O5MmjSJQw89lIULF3LHHXdU2k9E6m7dlm3kjJ7BpFc+BuAPJ/6UoklD6Ni6Wb2+bq3X\noQfuiy9q1p4gAwcOZP/999+j/Z133mHUqFEAdO3ale7du1f49bm5ueTl5QHQu3dvioqKAFiyZAlj\nx45l06ZNlJSUcNppp1UZx9y5cyO/DC644AL+9Kc/AaFpoxtvvJE5c+bQqFEj1qxZwzfffLPH11fW\n76CDDorvjRCRCt3yr2U88s6qyPEHYwbQpmXTBnnt1E3oHTuGplkqaq+lLl267DEnvmXLFr744gs6\nderEggULaN68ea3PD9C06e5vbOPGjSNTLhdeeCEvvPACPXr0YMqUKcyePbvac1W0rHDq1KmsX7+e\n+fPnk5WVRU5OToV33sbbT0TiU7ThO/rdOTtyPGbwkfz+xJ82aAypO+UyYQI0i/nzpVmzUHst9e/f\nn9LSUh5//HEAdu7cyTXXXMOFF15Is9jXitG3b1+efvppAJYtW8bixYtr9Npbt26lbdu2lJWVMTWO\n6wB9+/blqaeeAojqv3nzZg488ECysrKYNWsWq8O/9Fq2bMnWrVur7SciNXflkx9GJfOPxp3a4Mkc\nUjmhjxgBBQVwyCFgFvpcUBBqryUz4/nnn+eZZ56hc+fOHHbYYWRnZzNx4sRqv/ayyy5j/fr1dOnS\nhbFjx3LUUUex7777xv3at9xyC8ceeyx9+/bliCOOqLb/vffey/3330+3bt1Ys2ZNpH3EiBEUFhbS\nrVs3Hn/88ci5WrduTd++fenatSvXXXddpf1EJH5L1mwmZ/QMXlr0FQB3ntODoklD2Cc7mPpHFtSF\nsPz8fI/d4GL58uUceeSRgcRTVzt37qSsrIzs7GxWrlzJgAED+OSTT9hrr72CDq1OUvl7IlJfdu1y\nzi94n/8UfQvAfs2yeO+G/mRnNa731zaz+e6eX9FzqTuHnmRKS0s5+eSTKSsrw9154IEHUj6Zi8ie\n3l25gV89NC9y/OiF+ZxyxE8CjGg3JfQEadmypbbUE0ljZTt3MeCut1i9MbRc+oiDWjLjqhNo3Ch5\nah4poYuIVOPVJWu55IkFkeNpl/QhP2fP5ctBU0IXEanE9z/spOctr7GtLLSd8omHteGxi45O2kqk\nSugiIhX4x7wvuPH53cuP//3HEzn8oJYBRlS9uBO6mTUGCoE17j405rmmwOOE9hLdCJzn7kUJjFNE\npEFsKv2BvPGvR47P6d2eO87pEWBE8avJOvRRVL5X6MXAf929E3A3cHtdAwtK48aNycvLi3wUFRVR\nWFjIVVddBcDs2bN59913I/1feOEFli1bVuPXqazc7Y/t8ZbmFZHEuW/mZ1HJ/O3rT06ZZA5xjtDN\nrD0wBJgAXF1BlzOAceHH04D7zMw8Bas97b333ixcuDCqLScnh/z80LLP2bNn06JFC372s58BoYQ+\ndOhQunTpktA44i3NKyJ19/XmbRx325uR48tPPpTrTku9m+3iHaHfA1wP7Krk+XbAlwDuvgPYDLSu\nc3RJYvbs2QwdOpSioiImT57M3XffTV5eHm+99RbTp0/nuuuuIy8vj5UrV7Jy5UoGDRpE7969OeGE\nE/j441C1tcrK3VamfGneKVOmMHz4cAYNGkTnzp25/vrrI/1ee+01+vTpQ69evTjnnHMoKSmpnzdB\nJE3d/OKSqGQ+f+yAlEzmEMcI3cyGAuvcfb6Z9avLi5nZSGAkQMdqimj95aWlLPtqS11ebg9dDt6H\nm39+VJV9vv/++0g1xNzcXJ5//vnIczk5OVxyySW0aNGCa6+9FoBhw4YxdOjQyPRI//79mTx5Mp07\nd2bevHlcdtllzJw5M1Lu9je/+Q33339/jWNfuHAhH374IU2bNuXwww/nyiuvZO+99+bWW2/ljTfe\noHnz5tx+++3cdddd3HTTTdWfUCTDrVxfQv//3V0G+6ahXfh/x+cGGFHdxTPl0hcYZmaDgWxgHzN7\nwt1/Xa7PGqADUGxmTYB9CV0cjeLuBUABhG79r2vw9aGiKZd4lZSU8O6773LOOedE2rZv3w5UXu42\nXv3794/UhunSpQurV69m06ZNLFu2jL59+wLwww8/0KdPn1rFLpIp3J1Ln1jAq0u/jrQt+ctptGia\n+ov+qv0XuPsNwA0A4RH6tTHJHGA68FvgPeBsYGZd58+rG0kno127dtGqVatKfyHUZe1qbNndHTt2\n4O4MHDiQJ598stbnFckkHxVvYth9cyPH956fxxl57QKMKLFqXW3RzMab2bDw4SNAazNbQeii6ehE\nBJeMYsvQlj/eZ599yM3N5ZlnngFCI4FFixYBlZe7rYvjjjuOuXPnRnZT+u677/j0008Tcm6RdLJr\nl3Pm/XMjyfzAlk355NZBaZXMoYYJ3d1n/7gG3d1vcvfp4cfb3P0cd+/k7se4++f1EWwy+PnPf87z\nzz9PXl4eb7/9Nueffz533HEHPXv2ZOXKlUydOpVHHnmEHj16cNRRR0X26qys3G1dtGnThilTpvDL\nX/6S7t2706dPn8hFWBEJ+ce8L/jpjS+z8MtNAEy56Gj+M2YATZvUf2XEhqbyuVIlfU8kVZX+sIMu\nN/07ctyt3b68cHnfpCqmVRsqnysiGeWyqfN5efHui57jft6FC/um9gqWeCihi0ja2FCynfxb34hq\nW3Xb4KQtppVoSZfQ3T1j3vxkl4I3+koGG3TPHD7+eveChQdH9OL0bm0DjKjhJVVCz87OZuPGjbRu\n3VpJPWDuzsaNG8nOzg46FJEqfb6+hFPK3SAEUDRpSEDRBCupEnr79u0pLi5m/fr1QYcihH7Btm/f\nPugwRCqVM3pG1PGzl/ah9yHJt/FEQ0mqhJ6VlUVubvpfuBCRupm/+lvOevC9qLZMHZWXl1QJXUSk\nOrGj8jevOYlD21RcjjrTKKGLSEqI3dez84EteP3qkwKMKPkooYtIUnN3cm94OartgzEDaNOyaSVf\nkbmU0EUkaf197ir+8tLuHcFO73oQD/66d4ARJTcldBFJOmU7d9F5zCtRbcvGn0azvZSyqqJ3R0SS\nyviXlvHo3FWR40tOOpTRp6fmDkINTQldRJJCyfYddL3531FtKyacTpPGta7ynXGU0EUkcBdP+YA3\nP14XOb7lzK5ccNwhAUaUmuLZUzQbmAM0Dfef5u43x/S5ELiD0FZ0APe5+8OJDVVE0s26Lds4ZuKb\nUW2ZVEwr0eIZoW8HTnH3EjPLAt4xs1fc/f2Yfv909ysSH6KIpKOT7pjF6o2lkeOHf5PPgC4/CTCi\n1BfPnqIOlIQPs8IfKsMnIrXy2TdbGXj3nKg23bafGHFdbTCzxma2EFgHvO7u8yrodpaZfWRm08ys\nQ0KjFJG0kDN6RlQyf+HyvpmVzKdOhZwcaNQo9DlB+wv/KK6E7u473T0PaA8cY2ZdY7q8BOS4e3fg\ndeCxis5jZiPNrNDMClVRUSRzvP/5xqgaLE2bNKJo0hDyOrQKMKoGNnUqjBwJq1eDe+jzyJEJTeo1\n3lPUzG4CSt39zkqebwx86+77VnWeivYUFZH0E1tM663r+nFI6+YBRROgnJxQEo91yCFQVBT3aara\nU7TaEbqZtTGzVuHHewMDgY9j+pTfFmQYsDzu6EQkLb206KuoZN6t3b4UTRqSmckc4IsvatZeC/Gs\ncmkLPBYeeTcCnnb3f5nZeKDQ3acDV5nZMGAH8C1wYcIiFJGUUlExrQV/Hsj+zfcKKKIk0bFjxSP0\njh0T9hLVjtDd/SN37+nu3d29q7uPD7ffFE7muPsN7n6Uu/dw95Pd/eOqzyoi6ej/3loZlczPzDuY\noklDgkvm9XwRskYmTIBmzaLbmjULtSeI7hQVkTr7YccuDhsbXUzr41sGkZ3VOKCI2H0RsjS81v3H\ni5AAI0Y0fDw/vuaYMaFplo4dQ8k8gbHU+KJoouiiqEh6GPvCYp54f/c88FX9O3P1wMMCjCgsQRch\nk01VF0U1QheRWtmyrYzu416Lals5cTCNGyXJbfsNcBEy2Sihi0iN/frhebyzYkPk+PazunHe0Ym7\nuJcQDXARMtkooYtI3NZu/p4+t82MakvaOz0nTIieQ4eEX4RMNkroIhKXYye+wTdbtkeOp1x0NP0O\nPzDAiKrRABchk40SuohUafnaLZx+79tRbUk7Ko81YkRaJ/BY2gpEpCaSaV1zA8gZPSMqmf/ryuNT\nJ5lnII3QReKVbOua69HcFRsY8fDuoqr77p3FoptPDTAiiYfWoYvEK03XNceKLab19vUn02H/ZpX0\nloamdegiiZDm65qfW1DM1U8vihwfnbMfz1zyswAjkppSQheJV5qua961y/npjdHFtBbddCr7NssK\nKCKpLV0UFYlXAxRXamj3zfwsKpmfm9+eoklDlMxTlEboIvFKo3XN28p2csSfX41qC7yYltSZErpI\nTaTBuubrpy3i6cLiyPG1px7GFad0DjAiSRQldJEMsan0B/LGvx7V9vnEwTRKlmJaUmfVJnQzywbm\nAE3D/ae5+80xfZoCjwO9gY3Aee5elPBoRaRWYpci3n1eD37Rs31A0Uh9iWeEvh04xd1LzCwLeMfM\nXnH398v1uRj4r7t3MrPzgduB8+ohXhGpgWVfbWHw31L0tn2psWoTuofuPCoJH2aFP2LvRjoDGBd+\nPA24z8zMg7prSUT2GJVPGt6N849J7SWWUrW45tDDG0TPBzoB97v7vJgu7YAvAdx9h5ltBloDG2LO\nMxIYCdAxxdfuiiSrmR9/w/+bEn0XtkblmSGuhO7uO4E8M2sFPG9mXd19SU1fzN0LgAII3fpf068X\nkarFjsqfuPhYju98QEDRSEOr0Y1F7r4JmAUMinlqDdABwMyaAPsSujgqIg1gytxVeyTzoklDQsk8\nwypEZrJ4Vrm0AcrcfZOZ7Q0MJHTRs7zpwG+B94CzgZmaPxepf+5O7g3Rt+2//j8n0vknLUMHGVQh\nUuIbobcFZpnZR8AHwOvu/i8zG29mw8J9HgFam9kK4GpgdP2EKyI/+vMLS/ZI5kWThuxO5hC6q7X8\nFmwQOh4zpgEilIam8rkiKWbHzl10GvNKVFvh2AEc0KLpnp0bNYKK/o+bwa5d9RSh1KeqyueqOJdI\nfamHuesz758blczbtdqboklDKk7mUHklSK0yS0u69V+kPiR47rqi2/bjKqY1YUJ0HJDyFSKlcppy\nEakPCdzdKHb1ypFt9+GVUSfEf4KpU9OiQqSEaMpFtHStoSVgd6MV60r2SOafTxxcs2QOoeRdVBSa\nMy8qUjJPY5pyyQRautbw6ri7UWwiH3TUQUy+oHciIpM0phF6JtDStYZXy92N5ny6vsIbhJTMJR4a\noWeCNN/cOCnVYnej2ESujSekppTQM0Gabm6c9OLc3eixd4u4efrSqDYV05LaUELPBFq6lrRiR+WT\nf92LQV3bBhSNpDol9EyQRpsbp4sbnvuIJ//zZVSbRuVSV0romSINNjdOBxUV0/rXlcfTtd2+AUUk\n6USrXCT9Jcka/EH3zKmwmJaSuSSKRuiS3pJgDf72HTs5fOyrUW3/ubE/B+6T3SCvL5lDt/5Lekvg\nLfi1evmYi56guXKpm6pu/dcIXdJbQGvwN5RsJ//WN6La4iqmJVIH1c6hm1kHM5tlZsvMbKmZjaqg\nTz8z22xmC8MfN9VPuCI1FED52JzRM6KSee4BzSmaNKTuyTxJrgVI8opnhL4DuMbdF5hZS2C+mb3u\n7sti+r3t7kMTH6JIHTTgGvwFX/yX4Q+8G9W26rbBmFndT54E1wIk+VU7Qnf3te6+IPx4K7AcaFff\ngYkkxIgRUFAQmjM3C30uKEh4EswZPSMqmZ+RdzBFk4YkJpmD6vFIXGo0h25mOUBPYF4FT/cxs0XA\nV8C17r60gj4iDa8e1+A/U/gl1037KKqtXi56qh6PxCHuhG5mLYBngT+6+5aYpxcAh7h7iZkNBl4A\n9qgqZGYjgZEAHVVHRFJc7AqWi4/P5c9Du9TPi6kej8QhrhuLzCyLUDKf6u7PxT7v7lvcvST8+GUg\ny8wOqKBfgbvnu3t+mzZt6hi6SDBufnFJhSVu6y2ZQ63L8UpmqXaEbqFJwEeA5e5+VyV9DgK+cXc3\ns2MI/aLYmNBIRZJAbCK/69weDO/Vvv5fWPV4JA7xTLn0BS4AFpvZwnDbjUBHAHefDJwNXGpmO4Dv\ngfM9qDuWROrB4HvfZtna6JnGBr9BSPV4pBrVJnR3fweo8lK9u98H3JeooESSxa5dzk9vjK6/8sLl\nfcnr0CqgiEQqpztFRSqh2/Yl1Sihi8T4bvsOjrr531Ft827sz09UTEuSnBK6SDkalUsqU0IXAb78\ntpQT/jorqk3FtCTVKKFLxtOoXNKFErpkrPdWbuSXD70f1ZawYloiAVBCl4wUOyr/2aGt+cfvjwso\nGpHEUEKXjPL4e0Xc9GJ03ThNr0i6UEKXjBE7Kr/ylE5cc+rhAUUjknhK6JL27nnjU+5547OoNo3K\nJR0poUtaix2V3/+rXgzp3jagaETqlxK6pKXfPVbIG8u/iWrTqFzSXVz10EXqVQI3P965y8kZPSMq\nmc+85iQlc8kIGqFLsBK4+XHP8a/x39KyqDYlcskkFlTZ8vz8fC8sLAzktSWJ5ORUvLXaIYdAUVFc\npyjZvoOuMcW0Ft10Kvs2y6p7fCJJxszmu3t+Rc9phC7BquPmx7ptX2S3aufQzayDmc0ys2VmttTM\nRlXQx8zsb2a2wsw+MrNe9ROupJ3KNjmuZvPj4v+W7pHMP5twupK5ZLR4Rug7gGvcfYGZtQTmm9nr\n7r6sXJ/Tgc7hj2OBB8OfRao2YUL0HDpUu/lxbCI/Jmd/nr6kT31FKJIy4tmCbi2wNvx4q5ktB9oB\n5RP6GcDj4X1E3zezVmbWNvy1IpWrwebH81d/y1kPvhfVphG5yG41mkM3sxygJzAv5ql2wJfljovD\nbVEJ3cxGAiMBOlbzJ7VkkDg2P44dlf/u+FzGDu1Sn1GJpJy4E7qZtQCeBf7o7luq618Rdy8ACiC0\nyqU255DM8tyCYq5+elFUm0blIhWLK6GbWRahZD7V3Z+roMsaoEO54/bhNpFaix2V//Xs7pyb36GS\n3iJSbUK3ULX/R4Dl7n5XJd2mA1eY2VOELoZu1vy51NZtryzn/976PKpNo3KR6sUzQu8LXAAsNrOF\n4bYbgY4A7j4ZeBkYDKwASoGLEh+qZILYUfnTf+jDMbn7BxSNSGqJZ5XLO0CVe3KFV7dcnqigJPP8\n6qH3eXflxqg2jcpFakZ3ikqgduzcRacxr0S1vX39yXTYv1lAEYmkLiV0CUznMS9TtjN6sZNG5SK1\np4QuDW7z92X0+MtrUW2Lx51Ky2wV0xKpCyV0aVCxFz1bNG3Ckr+cFlA0IulFCV0axNebt3HcbW9G\nta2cOJjGjaq83i4iNaCELvUudlTe7/A2TLnomICiEUlf2oIukRK4lVo6WPrV5j2SedGkIemdzPUz\nIAHSCD1REriVWjqITeS3n9WN845O84Js+hmQgGkLukRJwFZq6eDN5d9w8WPR39eMWYqonwFpAFVt\nQacpl0Sp41Zq6SBn9IyoZD71d8fuTuaZMBWhnwEJmKZcEqVjx4pHZxlQ9/3vc1fxl5eWRbVFjcoz\nZSoig38GJDlohJ4oEyaEtk4rr5qt1FKdu5MzekZUMn/j6hP3nGIZMyZ6izkIHY8Z0wBRNqAM/BmQ\n5KKEnigjRkBBQWi+1Cz0uaCg4UagDTylMfaFxeTe8HJUW9GkIXQ6sOWenTNlKiLonwHJeLoomg5i\npzQgNDKsh2RSUTGtwrEDOKBF08q/SBcLRRJGF0XTXQNNaZz14LtRybzD/ntTNGlI1ckcNBUh0kDi\n2bHoUWAosM7du1bwfD/gRWBVuOk5dx+fyCClGvU8pbF1WxndxkUX0/r4lkFkZzWO7wQ//pUwZkwo\npo4dQ8lcUxEiCRXPKpcpwH3A41X0edvdhyYkIqm5elxdEVvi9vSuB/Hgr3vX/EQjRiiBi9SzeHYs\nmmNmOfUfitTahAkVz6HXYUqj+L+lHH/7rKi2zycOppGKaYkkrUStQ+9jZouAr4Br3X1pgs4r8Ujw\nlEbsbftX9e/M1QMPq2uUIlLPEpHQFwCHuHuJmQ0GXgA6V9TRzEYCIwE66maLxErAlMaiLzdxxv1z\no9oy5rZ9kTRQ54Tu7lvKPX7ZzB4wswPcfUMFfQuAAggtW6zra0vixI7K7zkvjzN7tgsoGhGpjTon\ndDM7CPjG3d3MjiG0FHJjNV8mSeLVJWu55IkFUW0alYukpniWLT4J9AMOMLNi4GYgC8DdJwNnA5ea\n2Q7ge+B8D+puJamR2FH503/owzG5+wcUjYjUVTyrXH5ZzfP3EVrWKCli8lsrmfTKx1FtGpWLpD5V\nW8wg7r5H/ZVZ1/Yj94DmAUUkIomkhJ4hrnl6Ec8uKI5q06hcJL2olktNpdhGDT/s2EXO6BlRyXzh\nTQOVzEXSkEboNZFiGzWcfu/bLF8bWVXKEQe15NU/nhhgRCJSn1Q+tyZSpAzs5tIyeoyPLqb1ya2D\naNokzmJaIpK0qiqfqxF6TaTARg2xSxF/0bMdd5+XF1A0ItKQUmsOPej568rKFSRBGYN1W7ftkcxX\n3TZYyVwkg6TOCD0Z5q/roaphIvT/39msXP9d5Pj6QYdzWb9OAUYkIkFInTn0ZJm/njo1aTZqWLGu\nhAF3vRXVptUrIumtqjn01EnojRpBRbGawa5diQssRcROrzx76c/ofch+AUUjIg0lPS6K1uOuPKnk\ng6JvOWfye5FjM1h1m0blIpJKCT1J568bUuyoXLfti0h5qbPKZcQIKCgIzZmbhT4XFCTlDT2JNuOj\ntVHJ/IiDWlI0aYiSuYhESZ0ROmTcRsMVFdMqHDuAA1o0DSgiEUlmqZXQM8jDb3/OrTOWR46HdGvL\n/SN6BRiRiCQ7JfQkU7ZzF53HvBLVtmz8aTTbS98qEalatXPoZvaoma0zsyWVPG9m9jczW2FmH5mZ\nhpG1NG760qhkflm/QymaNETJXETiEk+mmEJoR6LHK3n+dKBz+ONY4MHwZ4nT1m1ldBsXXUxr5cTB\nNG5kAUUkIqkoni3o5phZThVdzgAeD+8j+r6ZtTKztu6+NkExprXfPvof3vp0feR44i+68atjM2tt\nvYgkRiL+lm8HfFnuuDjctkdCN7ORwEiAjhl2Q1Csrzdv47jb3oxqW3XbYMw0KheR2mnQyVl3LwAK\nIHTrf0O+djI5/vaZFP/3+8jxI7/Np/+RPwkwIhFJB4lI6GuADuWO24fbJMan32zl1LvnRLWpmJaI\nJEoiEvp04Aoze4rQxdDNmj/fU+xt+y9e3pceHVoFFI2IpKNqE7qZPQn0Aw4ws2LgZiALwN0nAy8D\ng4EVQClwUX0Fm4reXbmBXz00L3LcfK/GLB0/KMCIRCRdxbPK5ZfVPO/A5QmLKI3EjsrnXHcyHVs3\nCygaEUl3umOlHry4cA2jngJkLp4AAAcASURBVFoYOe7RoRUvXt43wIhEJBMooSdQRcW0PvzzQPZr\nvldAEYlIJkmd8rlJ7sWFa6KS+fCe7SiaNETJXEQajEbodVRRMa1Pbh1E0yaNA4pIRDKVEnodFMxZ\nycSXP44c33F2d87J71DFV4iI1B8l9Fr4bvsOjrr531Ftn08cTCMV0xKRACmh19C0+cVc+8yiyPHf\nLzqakw8/MMCIRERClNDjtGVbGd3LlbjdO6sxy2/RDUIikjyU0OMQO1c++9p+5GiDZhFJMkroVVi3\ndRvHTNhd4vbi43P589AuAUYkIlI5JfRKTJixjIfeXhU5/s+N/Tlwn+wAIxIRqZoSeozVG7/jpDtm\nR47/NOgILu13aHABiYjESQm9nFFPfciLC7+KHC+6+VT23TsrwIhEROKnhA4s/WozQ/72TuT4r2d3\n51zdICQiKSajE7q7c37B+8xb9S0ALbOb8MGYAWRn6bZ9EUk9cRXnMrNBZvaJma0ws9EVPH+hma03\ns4Xhj98lPtTEev/zjeTe8HIkmT/0m3wWjztNyVxEUlY8OxY1Bu4HBgLFwAdmNt3dl8V0/ae7X1EP\nMSbUjp27GHj3HFZt+A6ATge24NVRJ9CksQpPikhqi2fK5Rhghbt/DhDeO/QMIDahJ71Xl3zNJU/M\njxw//Yc+HJO7f4ARiYgkTjwJvR3wZbnjYkKbQcc6y8xOBD4F/sfdv6ygTyC2le2k1y2vU/rDTgD6\ndmrNExcfi5mKaYlI+kjURdGXgCfdfbuZ/QF4DDgltpOZjQRGAnTs2DFBL121f37wBX96dnHk+JVR\nJ3Bk230a5LVFRBpSPAl9DVB+DV/7cFuEu28sd/gw8NeKTuTuBUABQH5+vtco0hraXFpGj/G7i2kN\n79WOu87Nq8+XFBEJVDwJ/QOgs5nlEkrk5wO/Kt/BzNq6+9rw4TBgeUKjrKH7Z63gjn9/Ejl++/qT\n6bB/swAjEhGpf9UmdHffYWZXAP8GGgOPuvtSMxsPFLr7dOAqMxsG7AC+BS6sx5gr9c2WbRw7cXcx\nrUtOOpTRpx8RRCgiIg3O3Ot15qNS+fn5XlhYmLDzjZu+lCnvFkWOPxgzgDYtmybs/CIiycDM5rt7\nfkXPpfydoqs2fMfJd86OHI8dciS/O+GnwQUkIhKQlE3o7s4V//iQGYvXRtoWjzuVltkqpiUimSkl\nE/ri4s38/L7dxbTuOrcHw3u1DzAiEZHgpVxC//Lb0kgyb918L+aOPkX1V0RESMGE3qJpE/p2as3F\nx+dyyhE/CTocEZGkkXIJfb/mezH1d8cFHYaISNJRiUERkTShhC4ikiaU0EVE0oQSuohImlBCFxFJ\nE0roIiJpQgldRCRNKKGLiKSJwMrnmtl6YHUcXQ8ANtRzOKlI70vl9N5UTO9L5VLpvTnE3dtU9ERg\nCT1eZlZYWe3fTKb3pXJ6byqm96Vy6fLeaMpFRCRNKKGLiKSJVEjoBUEHkKT0vlRO703F9L5ULi3e\nm6SfQxcRkfikwghdRETikJQJ3cw6mNksM1tmZkvNbFTQMSUTM2tsZh+a2b+CjiWZmFkrM5tmZh+b\n2XIz6xN0TMnCzP4n/H9piZk9aWbZQccUFDN71MzWmdmScm37m9nrZvZZ+PN+QcZYW0mZ0IEdwDXu\n3gU4DrjczLoEHFMyGQUsDzqIJHQv8Kq7HwH0QO8RAGbWDrgKyHf3rkBj4PxgowrUFGBQTNto4E13\n7wy8GT5OOUmZ0N19rbsvCD/eSug/Zrtgo0oOZtYeGAI8HHQsycTM9gVOBB4BcPcf3H1TsFEllSbA\n3mbWBGgGfBVwPIFx9znAtzHNZwCPhR8/BpzZoEElSFIm9PLMLAfoCcwLNpKkcQ9wPbAr6ECSTC6w\nHvh7eDrqYTNrHnRQycDd1wB3Al8Aa4HN7v5asFElnZ+4+9rw46+BlNywOKkTupm1AJ4F/ujuW4KO\nJ2hmNhRY5+7zg44lCTUBegEPuntP4DtS9M/mRAvPB59B6JfewUBzM/t1sFElLw8t/UvJ5X9Jm9DN\nLItQMp/q7s8FHU+S6AsMM7Mi4CngFDN7ItiQkkYxUOzuP/4lN41QghcYAKxy9/XuXgY8B/ws4JiS\nzTdm1hYg/HldwPHUSlImdDMzQnOhy939rqDjSRbufoO7t3f3HEIXtWa6u0ZagLt/DXxpZoeHm/oD\nywIMKZl8ARxnZs3C/7f6owvGsaYDvw0//i3wYoCx1FpSJnRCI9ELCI1AF4Y/BgcdlCS9K4GpZvYR\nkAdMDDiepBD+q2UasABYTOj/fVrcGVkbZvYk8B5wuJkVm9nFwCRgoJl9RugvmklBxlhbulNURCRN\nJOsIXUREakgJXUQkTSihi4ikCSV0EZE0oYQuIpImlNBFRNKEErqISJpQQhcRSRP/H0L19tc1pBYB\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wlduHeYJfd-",
        "colab_type": "text"
      },
      "source": [
        "## Doing the same thing as above but using the Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em9d41mCIANt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "9f8455fa-ca2d-4f2b-9289-5719214f3514"
      },
      "source": [
        "class ToyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        # Load Data \n",
        "        self.x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
        "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
        "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
        "\n",
        "        self.y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
        "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
        "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "        # 3. Return a data pair (e.g. image and label).\n",
        "        return (self.x_train[index], self.y_train[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return x_train.shape[0]\n",
        "\n",
        "# You can then use the prebuilt data loader. \n",
        "ds = ToyDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=ds,\n",
        "                                           batch_size=5, \n",
        "                                           shuffle=True)\n",
        "# Hyper-parameters\n",
        "input_size = 1\n",
        "output_size = 1\n",
        "num_epochs = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Linear regression model (1x1 linear layer)\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for x, y in train_loader:\n",
        "        \n",
        "        # Convert numpy arrays to torch tensors (No need to convert here since dataloader returns tensors)\n",
        "        inputs = x\n",
        "        targets = y\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "    \n",
        "        # Backward and optimize\n",
        "        # Zero gradients from previous iterations\n",
        "        optimizer.zero_grad()\n",
        "        # Backprop\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "\n",
        "# Plot the graph\n",
        "#Final predictions after training\n",
        "\n",
        "# Nice way to get entire daatset from a dataLoader\n",
        "x_train = ds[:][0]\n",
        "y_train = ds[:][1]\n",
        "\n",
        "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
        "# True graph\n",
        "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
        "# Predicted graph\n",
        "plt.plot(x_train, predicted, label='Fitted line')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [5/60], Loss: 2.0839\n",
            "Epoch [5/60], Loss: 1.9971\n",
            "Epoch [5/60], Loss: 1.4121\n",
            "Epoch [10/60], Loss: 0.1599\n",
            "Epoch [10/60], Loss: 0.7120\n",
            "Epoch [10/60], Loss: 0.0704\n",
            "Epoch [15/60], Loss: 0.0272\n",
            "Epoch [15/60], Loss: 0.4703\n",
            "Epoch [15/60], Loss: 0.0801\n",
            "Epoch [20/60], Loss: 0.0605\n",
            "Epoch [20/60], Loss: 0.1237\n",
            "Epoch [20/60], Loss: 0.3729\n",
            "Epoch [25/60], Loss: 0.3257\n",
            "Epoch [25/60], Loss: 0.0673\n",
            "Epoch [25/60], Loss: 0.1789\n",
            "Epoch [30/60], Loss: 0.0309\n",
            "Epoch [30/60], Loss: 0.3922\n",
            "Epoch [30/60], Loss: 0.1386\n",
            "Epoch [35/60], Loss: 0.3064\n",
            "Epoch [35/60], Loss: 0.0649\n",
            "Epoch [35/60], Loss: 0.1919\n",
            "Epoch [40/60], Loss: 0.2527\n",
            "Epoch [40/60], Loss: 0.0501\n",
            "Epoch [40/60], Loss: 0.2524\n",
            "Epoch [45/60], Loss: 0.3756\n",
            "Epoch [45/60], Loss: 0.0081\n",
            "Epoch [45/60], Loss: 0.1697\n",
            "Epoch [50/60], Loss: 0.0234\n",
            "Epoch [50/60], Loss: 0.3210\n",
            "Epoch [50/60], Loss: 0.2258\n",
            "Epoch [55/60], Loss: 0.3341\n",
            "Epoch [55/60], Loss: 0.2239\n",
            "Epoch [55/60], Loss: 0.0048\n",
            "Epoch [60/60], Loss: 0.2697\n",
            "Epoch [60/60], Loss: 0.2531\n",
            "Epoch [60/60], Loss: 0.0305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp4PDxO7Nmoc",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2zwWaRvN2LC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "7d41931e-d11c-498f-ddd3-eb697c40d2d7"
      },
      "source": [
        "# Hyper-parameters \n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset (images and labels)\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader (input pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "# Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "\n",
        "# Loss and optimizer\n",
        "# nn.CrossEntropyLoss() computes softmax internally\n",
        "criterion = nn.CrossEntropyLoss()  \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Reshape images to (batch_size, input_size)\n",
        "        # From (batch_size, 1, 28, 28) to (batch_size, 1, 28*28)\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 2.2022\n",
            "Epoch [1/5], Step [200/600], Loss: 2.0750\n",
            "Epoch [1/5], Step [300/600], Loss: 2.0048\n",
            "Epoch [1/5], Step [400/600], Loss: 1.9185\n",
            "Epoch [1/5], Step [500/600], Loss: 1.8528\n",
            "Epoch [1/5], Step [600/600], Loss: 1.8422\n",
            "Epoch [2/5], Step [100/600], Loss: 1.7191\n",
            "Epoch [2/5], Step [200/600], Loss: 1.6464\n",
            "Epoch [2/5], Step [300/600], Loss: 1.6298\n",
            "Epoch [2/5], Step [400/600], Loss: 1.4922\n",
            "Epoch [2/5], Step [500/600], Loss: 1.5216\n",
            "Epoch [2/5], Step [600/600], Loss: 1.4065\n",
            "Epoch [3/5], Step [100/600], Loss: 1.4516\n",
            "Epoch [3/5], Step [200/600], Loss: 1.3581\n",
            "Epoch [3/5], Step [300/600], Loss: 1.3408\n",
            "Epoch [3/5], Step [400/600], Loss: 1.2430\n",
            "Epoch [3/5], Step [500/600], Loss: 1.2801\n",
            "Epoch [3/5], Step [600/600], Loss: 1.2528\n",
            "Epoch [4/5], Step [100/600], Loss: 1.2563\n",
            "Epoch [4/5], Step [200/600], Loss: 1.2555\n",
            "Epoch [4/5], Step [300/600], Loss: 1.2521\n",
            "Epoch [4/5], Step [400/600], Loss: 1.1429\n",
            "Epoch [4/5], Step [500/600], Loss: 1.1269\n",
            "Epoch [4/5], Step [600/600], Loss: 1.0840\n",
            "Epoch [5/5], Step [100/600], Loss: 1.1231\n",
            "Epoch [5/5], Step [200/600], Loss: 1.0674\n",
            "Epoch [5/5], Step [300/600], Loss: 0.9796\n",
            "Epoch [5/5], Step [400/600], Loss: 1.1152\n",
            "Epoch [5/5], Step [500/600], Loss: 0.9802\n",
            "Epoch [5/5], Step [600/600], Loss: 0.9095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsw9ZYJ9SSyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7273851-d44c-4912-fc02-6301eaa49068"
      },
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Why is .data required? Removing it seems to make no difference\n",
        "        # .max() returns the max element along axis = 1\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 82 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk4xzLY0N0xq",
        "colab_type": "text"
      },
      "source": [
        "# Feed Forward Neural Network"
      ]
    }
  ]
}