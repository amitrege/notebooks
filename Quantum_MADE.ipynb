{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Quantum_MADE.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBU_vVRhwjsy"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.utils as vutils\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvR8_TpIFepg",
        "outputId": "784180c4-97eb-4e48-c534-59f2b12bebd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpFoAOrfFfYn"
      },
      "source": [
        "def setup_data(dir, num_circuits, file_prefix, dir_with_gates, separate_bits, norm = 'max_norm', pick_file = 'False', unique_circ_id = 'True'):\n",
        "  onlyfiles = next(os.walk(dir))[2] #dir is your directory path as string\n",
        "  print(pick_file)\n",
        "\n",
        "  # Currently, we only count files with frequencies\n",
        "  if not pick_file:\n",
        "    print(\"bsdjbc\")\n",
        "    if dir_with_gates:\n",
        "      num_files = int(math.ceil((len(onlyfiles) - 1)/3))\n",
        "    else:\n",
        "      num_files = len(onlyfiles)\n",
        "  else:\n",
        "    num_files = 1\n",
        "  print(pick_file)\n",
        "  for i in range(num_files): # Only FC files matter and there is an extra IDs file\n",
        "    # Give unique indexes to each circuit in each file      \n",
        "    idx = i*num_circuits\n",
        "    d = np.load(dir + \"/\" + file_prefix + str(i) + \".npy\", allow_pickle=True)\n",
        "    if not unique_circ_id:\n",
        "      circuits = np.concatenate(d[:,0]).reshape(d.shape[0],2)\n",
        "    else:\n",
        "      circuits = np.concatenate(d[:,0]).reshape(d.shape[0],2) + np.array([idx,idx+ int(num_circuits/2)]) \n",
        "\n",
        "    # Separate out cicruits and freq\n",
        "    d = d[:,1:]\n",
        "\n",
        "    # Stack\n",
        "    if i == 0:\n",
        "      det_c = np.copy(d)\n",
        "      circ = np.copy(circuits)\n",
        "    else:\n",
        "      det_c = np.vstack((det_c, d))\n",
        "      circ = np.vstack((circ, circuits))\n",
        "\n",
        "  # Separate out frequencies by setting on each bit (instead of settings on pairs)\n",
        "  if separate_bits == \"True\":\n",
        "    det_c_copy = np.empty(det_c.shape)\n",
        "\n",
        "    # 0 on qubit_0\n",
        "    det_c_copy[:,0] = det_c[:,0] + det_c[:,2]\n",
        "\n",
        "    # 1 on qubit_0\n",
        "    det_c_copy[:,1] = det_c[:,1] + det_c[:,3]\n",
        "\n",
        "    # 0 on qubit_1\n",
        "    det_c_copy[:,2] = det_c[:,0] + det_c[:,1]\n",
        "\n",
        "    # 1 on qubit_1\n",
        "    det_c_copy[:,3] = det_c[:,2] + det_c[:,3]\n",
        "\n",
        "    det_c = det_c_copy\n",
        "\n",
        "\n",
        "\n",
        "  # Normalize frequencies\n",
        "  if norm == \"max_norm\":\n",
        "    det_c = det_c/np.max(det_c)\n",
        "  elif norm == \"col_max_norm\":\n",
        "    det_c = det_c/det_c.max(axis = 0)\n",
        "  elif norm == \"row_norm\":\n",
        "    det_c = det_c/np.sum(det_c[0,:])\n",
        "\n",
        "  # Used only for testing\n",
        "  elif norm == \"no_norm\":\n",
        "    det_c = det_c\n",
        "\n",
        "  return circ, det_c\n",
        "\n",
        "def create_labels(label, size):\n",
        "  return np.full((size,), label)\n",
        "\n",
        "def create_dataset(features, label):\n",
        "  y = create_labels(label, features.shape[0])\n",
        "  return features, y\n",
        "\n",
        "def combine_datasets(x1, y1, x2, y2):\n",
        "  return np.vstack((x1,x2)), np.concatenate((y1,y2))\n",
        "\n",
        "def binary_comparison_data_pipeline(freq_1, freq_2, test_frac = 0.2):\n",
        "  x1, y1 = create_dataset(freq_1, 1)\n",
        "  x2, y2 = create_dataset(freq_2, 0)\n",
        "  x, y = combine_datasets(x1,y1, x2, y2)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "def svm_expt(freq_1, freq_2, test_size = 0.2):\n",
        "  X_train, X_test, y_train, y_test = binary_comparison_data_pipeline(freq_1, freq_2, test_frac = test_size)\n",
        "\n",
        "  clf = svm.SVC()\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  test_acc = (clf.predict(X_test) == y_test).mean()\n",
        "\n",
        "  return test_acc\n",
        "\n",
        "# Apply binary expt to all possible combinations of data_list and pretty print\n",
        "def create_expt_matrix(dataset_list, data_list, binary_expt):\n",
        "  num_datasets = len(data_list)\n",
        "\n",
        "  # get names of datasets\n",
        "  dataset_names = [d['dir_name'] for d in dataset_list]\n",
        "\n",
        "  expt_matrix = np.zeros((num_datasets, num_datasets))\n",
        "  for i in range(num_datasets):\n",
        "    for j in range(num_datasets):\n",
        "      if (j >= i) :\n",
        "        expt_matrix[i][j] = binary_expt(data_list[i][1], data_list[j][1])\n",
        "\n",
        "  # pretty printing\n",
        "  df = pd.DataFrame(expt_matrix, index=dataset_names, columns=dataset_names)\n",
        "  display(df)\n",
        "\n",
        "  return expt_matrix\n",
        "\n",
        "# Setup a list of data to be experimented on\n",
        "\n",
        "# dir_prefix - path to directory where all data is stored\n",
        "# f_prefix - prefix of file names with frequency data\n",
        "# dir_with_gates - True if data directory has gates included\n",
        "# sep_bits - if True, setup data such that frequency is calculated on each result bit instead of result pairs\n",
        "# normalize - Normalization scheme used\n",
        "def setup_datalist(datasets, dir_prefix, f_prefix, sep_bits, normalize):\n",
        "  data_list = []\n",
        "  data_list.append(setup_data(dir_prefix + datasets[0]['dir_name'],  num_circuits = datasets[0]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[0]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[1]['dir_name'],  num_circuits = datasets[1]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[1]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[2]['dir_name'],  num_circuits = datasets[2]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[2]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[3]['dir_name'],  num_circuits = datasets[3]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[3]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[4]['dir_name'],  num_circuits = datasets[4]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[4]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[5]['dir_name'],  num_circuits = datasets[5]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[5]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[6]['dir_name'],  num_circuits = datasets[6]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[6]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[7]['dir_name'],  num_circuits = datasets[7]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[7]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "  data_list.append(setup_data(dir_prefix + datasets[8]['dir_name'],  num_circuits = datasets[8]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[8]['dir_with_gates'], separate_bits = sep_bits, norm = normalize))\n",
        "\n",
        "  return data_list"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_yqty4dFoBy"
      },
      "source": [
        "datasets = [\n",
        "            {\n",
        "              'dir_name':\"IdealGates\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':True\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"Operation Crosstalk 1 (a)\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':False\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"Operation Crosstalk 2 (b)\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':False\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"Detection Crosstalk (c)\",\n",
        "              'num_circuits':40,\n",
        "              'dir_with_gates':False\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"XT1WithGates\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':True\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"XT2WithGates\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':True\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"DetX400\",\n",
        "              'num_circuits':40,\n",
        "              'dir_with_gates':True\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"DetXWithGates\",\n",
        "              'num_circuits':40,\n",
        "              'dir_with_gates':True\n",
        "            },\n",
        "            {\n",
        "              'dir_name':\"DetX100\",\n",
        "              'num_circuits':20,\n",
        "              'dir_with_gates':True\n",
        "            }\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb85h-3iFxLu"
      },
      "source": [
        "dir_prefix = \"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/\"\n",
        "f_prefix = \"FCTexts_\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B05nsr6wIA10",
        "outputId": "a50a3af9-0ed2-46d7-fa32-7c2c93ec2060",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sep_bits = False\n",
        "normalize = \"no_norm\"\n",
        "pf = 'False'\n",
        "ucid = 'True'\n",
        "ideal_circuits, ideal_freq = setup_data(dir_prefix + datasets[0]['dir_name'],  num_circuits = datasets[0]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[0]['dir_with_gates'], separate_bits = sep_bits, norm = normalize, pick_file = pf, unique_circ_id=ucid)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdbFnk0MMWds",
        "outputId": "776080a3-8be4-4061-8721-a3f96ce49c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ideal_freq.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR1EMOkeFtNi",
        "outputId": "0c119809-0290-44f1-eb87-b1b8f006f497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "ideal_circuits, ideal_freq = setup_data(dir_prefix + datasets[0]['dir_name'],  num_circuits = datasets[0]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[0]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[1]['dir_name'],  num_circuits = datasets[1]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[1]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[2]['dir_name'],  num_circuits = datasets[2]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[2]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[3]['dir_name'],  num_circuits = datasets[3]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[3]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[4]['dir_name'],  num_circuits = datasets[4]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[4]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[5]['dir_name'],  num_circuits = datasets[5]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[5]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[6]['dir_name'],  num_circuits = datasets[6]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[6]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[7]['dir_name'],  num_circuits = datasets[7]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[7]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)\n",
        "setup_data(dir_prefix + datasets[8]['dir_name'],  num_circuits = datasets[8]['num_circuits'], file_prefix = f_prefix, dir_with_gates = datasets[8]['dir_with_gates'], separate_bits = sep_bits, norm = normalize)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1b1c9c85ea86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mideal_circuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mideal_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/IdealGates\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma_circuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/Operation Crosstalk 1 (a)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_with_gates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb_circuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/Operation Crosstalk 2 (b)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_with_gates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc_circuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/Detection Crosstalk (c)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_circuits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_with_gates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetx400_circuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetx400_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gdrive/MyDrive/QuSense/Papers/Simulated-Data-Sarovar/DetX400\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_circuits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: setup_data() missing 4 required positional arguments: 'num_circuits', 'file_prefix', 'dir_with_gates', and 'separate_bits'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8E64pO8Ikmw"
      },
      "source": [
        "def gen_data_2(data, circ, frac):\n",
        "  data = data * (frac)\n",
        "  data = data.astype('int')\n",
        "  ds_size =  np.sum(data)\n",
        "  ds_size_column = np.cumsum(data, axis = 1)\n",
        "  arr = np.zeros((ds_size, 4))\n",
        "\n",
        "  running_sum = 0\n",
        "  for i in range(circ.shape[0]):\n",
        "    arr[running_sum :running_sum + ds_size_column[i][0],:] = [circ[i][0],0,circ[i][1],0]\n",
        "    arr[running_sum + ds_size_column[i][0]:running_sum + ds_size_column[i][1],:] = [circ[i][0],1,circ[i][1],0]\n",
        "    arr[running_sum + ds_size_column[i][1]:running_sum + ds_size_column[i][2],:] = [circ[i][0],0,circ[i][1],1]\n",
        "    arr[running_sum + ds_size_column[i][2]:running_sum + ds_size_column[i][3],:] = [circ[i][0],1,circ[i][1],1]\n",
        "    running_sum += np.sum(data[i])\n",
        "  np.random.shuffle(arr)\n",
        "  return arr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMF1AeX3IrHK"
      },
      "source": [
        "a = gen_data_2(ideal_freq[:100], ideal_circuits[:100], 0.01)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEx1CdRrI3RX",
        "outputId": "e63d54ef-9510-44e5-ed12-ea8988077199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a[:100]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8.,  0., 17.,  1.],\n",
              "       [ 7.,  0., 15.,  1.],\n",
              "       [ 9.,  0., 16.,  1.],\n",
              "       [ 0.,  1., 16.,  0.],\n",
              "       [ 9.,  0., 17.,  1.],\n",
              "       [ 5.,  0., 14.,  1.],\n",
              "       [ 5.,  0., 16.,  1.],\n",
              "       [ 4.,  1., 18.,  0.],\n",
              "       [ 7.,  0., 10.,  1.],\n",
              "       [ 5.,  1., 14.,  0.],\n",
              "       [ 2.,  1., 10.,  0.],\n",
              "       [ 7.,  0., 12.,  0.],\n",
              "       [ 3.,  0., 12.,  1.],\n",
              "       [ 4.,  0., 13.,  0.],\n",
              "       [ 3.,  1., 19.,  1.],\n",
              "       [ 1.,  1., 11.,  1.],\n",
              "       [ 7.,  0., 16.,  0.],\n",
              "       [ 3.,  0., 18.,  1.],\n",
              "       [ 8.,  1., 15.,  1.],\n",
              "       [ 3.,  1., 11.,  1.],\n",
              "       [ 3.,  1., 12.,  1.],\n",
              "       [ 3.,  1., 19.,  1.],\n",
              "       [ 3.,  0., 15.,  0.],\n",
              "       [ 3.,  1., 19.,  1.],\n",
              "       [ 9.,  0., 15.,  1.],\n",
              "       [ 4.,  1., 10.,  0.],\n",
              "       [ 6.,  0., 14.,  0.],\n",
              "       [ 3.,  1., 16.,  1.],\n",
              "       [ 7.,  0., 15.,  1.],\n",
              "       [ 8.,  1., 12.,  1.],\n",
              "       [ 7.,  0., 10.,  1.],\n",
              "       [ 5.,  1., 15.,  1.],\n",
              "       [ 5.,  0., 15.,  1.],\n",
              "       [ 5.,  1., 17.,  1.],\n",
              "       [ 9.,  0., 10.,  1.],\n",
              "       [ 6.,  0., 18.,  0.],\n",
              "       [ 1.,  0., 13.,  0.],\n",
              "       [ 8.,  1., 15.,  1.],\n",
              "       [ 5.,  0., 17.,  1.],\n",
              "       [ 9.,  0., 10.,  0.],\n",
              "       [ 9.,  0., 13.,  0.],\n",
              "       [ 3.,  0., 12.,  0.],\n",
              "       [ 4.,  0., 17.,  1.],\n",
              "       [ 8.,  0., 10.,  1.],\n",
              "       [ 4.,  0., 14.,  0.],\n",
              "       [ 7.,  0., 10.,  0.],\n",
              "       [ 4.,  0., 13.,  0.],\n",
              "       [ 5.,  1., 16.,  1.],\n",
              "       [ 4.,  0., 18.,  0.],\n",
              "       [ 2.,  1., 10.,  1.],\n",
              "       [ 5.,  1., 17.,  1.],\n",
              "       [ 8.,  0., 10.,  0.],\n",
              "       [ 9.,  0., 15.,  0.],\n",
              "       [ 8.,  0., 16.,  1.],\n",
              "       [ 9.,  0., 19.,  1.],\n",
              "       [ 7.,  0., 15.,  1.],\n",
              "       [ 4.,  0., 17.,  1.],\n",
              "       [ 2.,  0., 10.,  1.],\n",
              "       [ 9.,  0., 10.,  1.],\n",
              "       [ 6.,  0., 18.,  0.],\n",
              "       [ 8.,  1., 16.,  0.],\n",
              "       [ 2.,  1., 12.,  0.],\n",
              "       [ 5.,  1., 14.,  0.],\n",
              "       [ 2.,  1., 13.,  0.],\n",
              "       [ 5.,  0., 17.,  1.],\n",
              "       [ 5.,  0., 10.,  0.],\n",
              "       [ 3.,  0., 19.,  1.],\n",
              "       [ 4.,  0., 18.,  1.],\n",
              "       [ 3.,  0., 19.,  1.],\n",
              "       [ 4.,  0., 13.,  0.],\n",
              "       [ 9.,  0., 15.,  0.],\n",
              "       [ 6.,  0., 18.,  0.],\n",
              "       [ 4.,  0., 13.,  0.],\n",
              "       [ 3.,  0., 11.,  1.],\n",
              "       [ 8.,  1., 18.,  1.],\n",
              "       [ 2.,  0., 12.,  1.],\n",
              "       [ 3.,  1., 11.,  1.],\n",
              "       [ 8.,  1., 16.,  1.],\n",
              "       [ 3.,  0., 18.,  1.],\n",
              "       [ 8.,  1., 15.,  1.],\n",
              "       [ 4.,  1., 18.,  0.],\n",
              "       [ 2.,  0., 19.,  1.],\n",
              "       [ 9.,  0., 15.,  0.],\n",
              "       [ 3.,  1., 11.,  0.],\n",
              "       [ 0.,  1., 15.,  0.],\n",
              "       [ 4.,  1., 14.,  0.],\n",
              "       [ 9.,  0., 12.,  1.],\n",
              "       [ 1.,  0., 10.,  0.],\n",
              "       [ 5.,  1., 12.,  1.],\n",
              "       [ 8.,  1., 13.,  0.],\n",
              "       [ 8.,  0., 12.,  0.],\n",
              "       [ 9.,  0., 18.,  1.],\n",
              "       [ 8.,  1., 17.,  1.],\n",
              "       [ 6.,  0., 19.,  1.],\n",
              "       [ 1.,  1., 11.,  1.],\n",
              "       [ 4.,  0., 10.,  0.],\n",
              "       [ 8.,  1., 10.,  1.],\n",
              "       [ 8.,  0., 16.,  1.],\n",
              "       [ 7.,  0., 16.,  0.],\n",
              "       [ 7.,  0., 13.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}